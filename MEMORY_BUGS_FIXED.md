# ë©”ëª¨ë¦¬ ë²„ê·¸ ë¶„ì„ ë° ìˆ˜ì • ì‚¬í•­

## ğŸ” ë°œê²¬ëœ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë²„ê·¸

### 1. **STFT ë³€í™˜ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜** (Critical! ğŸ”¥)
**ìœ„ì¹˜**: `models/mss_tflocoformer.py` - `forward()` ë©”ì„œë“œ

**ë¬¸ì œ**:
```python
spec = self.transform.stft(mixture)  # 80GB spectrogram!
batch = torch.stack([spec.real, spec.imag], dim=1)  # specì€ ê³„ì† ë©”ëª¨ë¦¬ì— ë‚¨ì•„ìˆìŒ
```

**ì›ì¸**: 
- 10ì´ˆ ì˜¤ë””ì˜¤ â†’ 430 time frames Ã— 2049 freq bins
- spec í…ì„œê°€ stack í›„ì—ë„ ë©”ëª¨ë¦¬ì— ë‚¨ì•„ìˆìŒ
- real/imag ë³µì‚¬ë³¸ê¹Œì§€ ìƒì„±ë˜ì–´ **3ë°°ì˜ ë©”ëª¨ë¦¬ ì‚¬ìš©!**

**ìˆ˜ì •**:
```python
spec = self.transform.stft(mixture)
spec_real = spec.real
spec_imag = spec.imag
del spec  # ì¦‰ì‹œ ì‚­ì œ!

batch = torch.stack([spec_real, spec_imag], dim=1)
del spec_real, spec_imag  # ì¦‰ì‹œ ì‚­ì œ!
```

**ì ˆê° íš¨ê³¼**: ~40GB ë©”ëª¨ë¦¬ ì ˆì•½

---

### 2. **iSTFT ë£¨í”„ ë©”ëª¨ë¦¬ ëˆ„ì ** (Major!)
**ìœ„ì¹˜**: `models/mss_tflocoformer.py` - `forward()` ë©”ì„œë“œ

**ë¬¸ì œ**:
```python
for i, name in enumerate(source_names):
    audio = self.transform.istft(batch[:, i], length=original_length)
    sources[name] = audio
# batch í…ì„œê°€ ë£¨í”„ ë™ì•ˆ ê³„ì† ë©”ëª¨ë¦¬ì—!
```

**ì›ì¸**: 4ê°œ ì†ŒìŠ¤ Ã— ê°ê° spectrogram â†’ ëˆ„ì  ë©”ëª¨ë¦¬

**ìˆ˜ì •**:
```python
for i, name in enumerate(source_names):
    source_spec = batch[:, i].contiguous()
    audio = self.transform.istft(source_spec, length=original_length)
    sources[name] = audio
    del source_spec  # ê° ë°˜ë³µë§ˆë‹¤ ì‚­ì œ!

del batch  # ë£¨í”„ ëë‚˜ë©´ ì¦‰ì‹œ ì‚­ì œ!
```

**ì ˆê° íš¨ê³¼**: ~20GB ë©”ëª¨ë¦¬ ì ˆì•½

---

### 3. **Attention Q/K/V ë©”ëª¨ë¦¬ ëˆ„ìˆ˜** (Critical!)
**ìœ„ì¹˜**: `models/mss_tflocoformer.py` - `MultiHeadSelfAttention.forward()`

**ë¬¸ì œ**:
```python
query, key, value = self.get_qkv(input)

if self.rope is not None:
    query, key = self.apply_rope(query, key)  # ì›ë³¸ query, keyê°€ ë‚¨ì•„ìˆìŒ!

output = F.scaled_dot_product_attention(query, key, value, ...)
# Q, K, Vê°€ attention í›„ì—ë„ ë©”ëª¨ë¦¬ì—!
```

**ì›ì¸**: 
- Attention ê³„ì‚° ì¤‘ Q, K, Vê°€ ê³„ì† ë©”ëª¨ë¦¬ì— ìœ ì§€
- RoPE ì ìš© ì‹œ ìƒˆë¡œìš´ í…ì„œ ìƒì„±í•˜ì§€ë§Œ ì›ë³¸ ë¯¸ì‚­ì œ
- **8 layers Ã— 2 paths = 16ë²ˆ ëˆ„ì !**

**ìˆ˜ì •**:
```python
query, key, value = self.get_qkv(input)

if self.rope is not None:
    query_rope, key_rope = self.apply_rope(query, key)
    del query, key  # ì›ë³¸ ì‚­ì œ!
    query, key = query_rope, key_rope
    del query_rope, key_rope

output = F.scaled_dot_product_attention(query, key, value, ...)
del query, key, value  # Attention ì§í›„ ì¦‰ì‹œ ì‚­ì œ!
```

**ì ˆê° íš¨ê³¼**: ~30GB ë©”ëª¨ë¦¬ ì ˆì•½ (16 layers ëˆ„ì )

---

### 4. **ë°ì´í„°ì…‹ ë¦¬ìƒ˜í”Œë§ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜** (Minor but adds up)
**ìœ„ì¹˜**: `data/mss_dataset.py` - `__getitem__()`

**ë¬¸ì œ**:
```python
mixture, sr = torchaudio.load(mixture_path)
if sr != self.sample_rate:
    resampler = torchaudio.transforms.Resample(sr, self.sample_rate)
    mixture = resampler(mixture)  # ì›ë³¸ mixtureê°€ ë©”ëª¨ë¦¬ì—!
    # resampler ê°ì²´ë„ ê³„ì† ë©”ëª¨ë¦¬ì—!
```

**ì›ì¸**: 
- 44.1kHz â†’ 44.1kHz ë³€í™˜ ì‹œì—ë„ ìƒˆ í…ì„œ ìƒì„±
- ì›ë³¸ê³¼ ë³€í™˜ë³¸ì´ ëª¨ë‘ ë©”ëª¨ë¦¬ì— ìœ ì§€
- 4ê°œ ì†ŒìŠ¤ Ã— 2 (mixture + source) = 8ë²ˆ ë°œìƒ

**ìˆ˜ì •**:
```python
mixture, sr = torchaudio.load(mixture_path)
if sr != self.sample_rate:
    resampler = torchaudio.transforms.Resample(sr, self.sample_rate)
    mixture_resampled = resampler(mixture)
    del mixture  # ì›ë³¸ ì‚­ì œ!
    mixture = mixture_resampled
    del resampler  # Resampler ê°ì²´ ì‚­ì œ!
```

**ì ˆê° íš¨ê³¼**: ~5GB ë©”ëª¨ë¦¬ ì ˆì•½

---

### 5. **Encoder/Decoder ì¤‘ê°„ activation ëˆ„ì ** (Major!)
**ìœ„ì¹˜**: `models/mss_tflocoformer.py` - `forward()` ë©”ì„œë“œ

**ë¬¸ì œ**:
```python
for block in self.blocks:
    batch = block(batch)  # ëª¨ë“  ë ˆì´ì–´ì˜ activationì´ backwardë¥¼ ìœ„í•´ ìœ ì§€ë¨!
```

**ì›ì¸**: 
- Backward passë¥¼ ìœ„í•´ ëª¨ë“  ì¤‘ê°„ activation ì €ì¥
- 8 layers Ã— ê°ê° ìˆ˜ GB = **ì—„ì²­ë‚œ ëˆ„ì !**

**ìˆ˜ì •**:
```python
for idx, block in enumerate(self.blocks):
    batch = block(batch)
    # ì£¼ê¸°ì ìœ¼ë¡œ ìºì‹œ ì •ë¦¬
    if idx % 2 == 0 and torch.cuda.is_available():
        torch.cuda.empty_cache()
```

**ì ˆê° íš¨ê³¼**: í”„ë˜ê·¸ë©˜í…Œì´ì…˜ ê°ì†Œë¡œ ~10GB ì ˆì•½

---

## ğŸ“Š ì´ ë©”ëª¨ë¦¬ ì ˆê° íš¨ê³¼

| ë²„ê·¸ | ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ëŸ‰ | ìˆ˜ì • í›„ ì ˆê° | ìš°ì„ ìˆœìœ„ |
|-----|-------------|------------|---------|
| STFT ë³€í™˜ ëˆ„ìˆ˜ | ~40GB | âœ… 40GB | ğŸ”´ Critical |
| Attention Q/K/V | ~30GB | âœ… 30GB | ğŸ”´ Critical |
| iSTFT ë£¨í”„ | ~20GB | âœ… 20GB | ğŸŸ¡ Major |
| Encoder/Decoder | ~10GB | âœ… 10GB | ğŸŸ¡ Major |
| ë°ì´í„°ì…‹ ë¦¬ìƒ˜í”Œë§ | ~5GB | âœ… 5GB | ğŸŸ¢ Minor |
| **ì´í•©** | **~105GB** | **~105GB** | - |

## âœ… ì˜ˆìƒ ê²°ê³¼

### ìˆ˜ì • ì „
```
Ultra-Safe ì„¤ì • (3ì´ˆ, ì‘ì€ ëª¨ë¸)
ì˜ˆìƒ: 15-20GB
ì‹¤ì œ: 80-100GB âŒ (ë²„ê·¸ë¡œ ì¸í•œ 5ë°° ë©”ëª¨ë¦¬ ì‚¬ìš©!)
```

### ìˆ˜ì • í›„
```
Ultra-Safe ì„¤ì • (3ì´ˆ, ì‘ì€ ëª¨ë¸)
ì˜ˆìƒ: 15-20GB
ì‹¤ì œ: 15-20GB âœ… (ì •ìƒ!)

Memory-Optimized ì„¤ì • (5ì´ˆ, ì¤‘ê°„ ëª¨ë¸)
ì˜ˆìƒ: 30-40GB
ì‹¤ì œ: 30-40GB âœ… (ì •ìƒ!)
```

## ğŸš€ ì¦‰ì‹œ í…ŒìŠ¤íŠ¸

ìˆ˜ì •ëœ ì½”ë“œë¡œ ë‹¤ì‹œ ì‹¤í–‰:

```bash
# Ultra-Safe (ì´ì œ ì •ë§ ì•ˆì „í•¨!)
python training/train.py --config configs/musdb18_ultra_safe.yaml
```

ì˜ˆìƒ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:
- ì´ˆê¸° GPU ë©”ëª¨ë¦¬: 0.2GB
- ì²« ë°°ì¹˜ ë¡œë”©: +5GB (ë°ì´í„°)
- Forward pass: +10GB (ëª¨ë¸ activation)
- Backward pass: +5GB (gradients)
- **ì´í•©: ~20GB âœ…**

## ğŸ” ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§

í•™ìŠµ ì‹œì‘ í›„ í™•ì¸:
```bash
watch -n 1 nvidia-smi
```

ê¸°ëŒ€í•˜ëŠ” ì¶œë ¥:
```
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   PID   Type   Process name                              GPU Memory |
|        ID                                                      Usage      |
|=============================================================================|
|    0   1685    C   python                                       18-25GB   |
+-----------------------------------------------------------------------------+
```

## ğŸ’¡ ì¶”ê°€ ë””ë²„ê¹…

ì—¬ì „íˆ ë¬¸ì œê°€ ìˆë‹¤ë©´:

### 1. ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§
```python
import torch

# train.pyì˜ train_epoch í•¨ìˆ˜ì— ì¶”ê°€
def train_epoch(...):
    for batch_idx, batch in enumerate(pbar):
        if batch_idx == 0:  # ì²« ë°°ì¹˜ë§Œ
            print(f"Before forward: {torch.cuda.memory_allocated()/1e9:.2f}GB")
        
        predictions = model(mixture, return_time_domain=True)
        
        if batch_idx == 0:
            print(f"After forward: {torch.cuda.memory_allocated()/1e9:.2f}GB")
        
        loss = criterion(predictions, targets)['total_loss']
        
        if batch_idx == 0:
            print(f"After loss: {torch.cuda.memory_allocated()/1e9:.2f}GB")
        
        loss.backward()
        
        if batch_idx == 0:
            print(f"After backward: {torch.cuda.memory_allocated()/1e9:.2f}GB")
```

### 2. ë©”ëª¨ë¦¬ ìŠ¤ëƒ…ìƒ·
```python
import torch

# OOM ë°œìƒ ì‹œ
print(torch.cuda.memory_summary())
```

### 3. ë”ìš± ì•ˆì „í•œ ì„¤ì •
segment_lengthë¥¼ ë” ì¤„ì´ê¸°:
```yaml
dataset:
  segment_length: 88200  # 2ì´ˆ (ë§¤ìš° ì•ˆì „)
```

---

**ê²°ë¡ **: ë©”ëª¨ë¦¬ ë²„ê·¸ ìˆ˜ì •ìœ¼ë¡œ Ultra-Safe ì„¤ì •ì´ ì´ì œ ì§„ì§œë¡œ ì•ˆì „í•´ì¡ŒìŠµë‹ˆë‹¤! ğŸ‰
